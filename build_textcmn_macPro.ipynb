{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Desktop/text_cmn\n"
     ]
    }
   ],
   "source": [
    "cd ~/Desktop/text_cmn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concate_files(output_file,filenames,path):\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        for fname in filenames:\n",
    "            with open(path+fname) as infile:\n",
    "                outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['DIL', 'DOH', 'SUC', 'RUO', 'WAJ', 'XIH', 'CHJ', 'TIK', 'XIN', 'KOF', 'FAJ', 'SHH', 'XUL', 'LIS', 'CHX', 'XIY', 'MAK', 'HAT', 'XIJ', 'OUT'])\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "\n",
    "path='data/'\n",
    "\n",
    "#all txt concatenate for a single speaker\n",
    "all_txt=[f for f in listdir(path) if f.endswith('.txt')]\n",
    "all_speaker=set([s[:3] for s in all_txt])\n",
    "print all_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spk in all_speaker:\n",
    "    spk_txts=[f for f in all_txt if f.startswith(spk)]\n",
    "    output_file=spk+'_all.txt'\n",
    "    concate_files(output_file,spk_txts,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_data(suffix,path):\n",
    "    all_txt=[f for f in listdir(path) if f.endswith(suffix)]\n",
    "    all_speaker=set([s[:3] for s in all_txt])\n",
    "    print all_speaker\n",
    "    for spk in all_speaker:\n",
    "        spk_txts=[f for f in all_txt if f.startswith(spk)]\n",
    "        output_file=spk+'_all'+suffix\n",
    "        concate_files(output_file,spk_txts,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHJ_all.txt        KOF_all.txt        SUC_all.txt        XIY_all.txt\r\n",
      "CHX_all.txt        LIS_all.txt        TIK_all.txt        XUL_all.txt\r\n",
      "DIL_all.txt        MAK_all.txt        WAJ_all.txt        build_text_cmn.py\r\n",
      "DOH_all.txt        OUT_all.txt        XIH_all.txt        \u001b[1m\u001b[34mdata\u001b[m\u001b[m/\r\n",
      "FAJ_all.txt        RUO_all.txt        XIJ_all.txt\r\n",
      "HAT_all.txt        SHH_all.txt        XIN_all.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flist=[f for f in listdir('/Users/zangsir/Desktop/text_cmn/') if f.endswith('all.txt')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHJ_all.txt',\n",
       " 'CHX_all.txt',\n",
       " 'DIL_all.txt',\n",
       " 'DOH_all.txt',\n",
       " 'FAJ_all.txt',\n",
       " 'HAT_all.txt',\n",
       " 'KOF_all.txt',\n",
       " 'LIS_all.txt',\n",
       " 'MAK_all.txt',\n",
       " 'OUT_all.txt',\n",
       " 'RUO_all.txt',\n",
       " 'SHH_all.txt',\n",
       " 'SUC_all.txt',\n",
       " 'TIK_all.txt',\n",
       " 'WAJ_all.txt',\n",
       " 'XIH_all.txt',\n",
       " 'XIJ_all.txt',\n",
       " 'XIN_all.txt',\n",
       " 'XIY_all.txt',\n",
       " 'XUL_all.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_cmn/CHJ_all.txt\n",
      "text_cmn/CHX_all.txt\n",
      "text_cmn/DIL_all.txt\n",
      "text_cmn/DOH_all.txt\n",
      "text_cmn/FAJ_all.txt\n",
      "text_cmn/HAT_all.txt\n",
      "text_cmn/KOF_all.txt\n",
      "text_cmn/LIS_all.txt\n",
      "text_cmn/MAK_all.txt\n",
      "text_cmn/OUT_all.txt\n",
      "text_cmn/RUO_all.txt\n",
      "text_cmn/SHH_all.txt\n",
      "text_cmn/SUC_all.txt\n",
      "text_cmn/TIK_all.txt\n",
      "text_cmn/WAJ_all.txt\n",
      "text_cmn/XIH_all.txt\n",
      "text_cmn/XIJ_all.txt\n",
      "text_cmn/XIN_all.txt\n",
      "text_cmn/XIY_all.txt\n",
      "text_cmn/XUL_all.txt\n"
     ]
    }
   ],
   "source": [
    "for f in flist:\n",
    "    print 'text_cmn/'+f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# let's check if the conll_merged files have the same number of lines as they should in the original number of files for a single speaker. if not, then there is a sentence segmentation problem by the stanford parser and we need to redo it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Downloads/stanford-corenlp-full-2016-10-31/coref\n"
     ]
    }
   ],
   "source": [
    "cd ~/Downloads/stanford-corenlp-full-2016-10-31/coref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Downloads/stanford-corenlp-full-2016-10-31/coref/conll_xml\n"
     ]
    }
   ],
   "source": [
    "cd conll_xml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHJ_all.txt.conll   HAT_all.txt.xml     SHH_all.txt.conll   XIH_all.txt.xml\r\n",
      "CHJ_all.txt.xml     KOF_all.txt.conll   SHH_all.txt.xml     XIJ_all.txt.conll\r\n",
      "CHX_all.txt.conll   KOF_all.txt.xml     SUC_all.txt.conll   XIJ_all.txt.xml\r\n",
      "CHX_all.txt.xml     LIS_all.txt.conll   SUC_all.txt.xml     XIN_all.txt.conll\r\n",
      "DIL_all.txt.conll   LIS_all.txt.xml     TIK_all.txt.conll   XIN_all.txt.xml\r\n",
      "DIL_all.txt.xml     MAK_all.txt.conll   TIK_all.txt.xml     XIY_all.txt.conll\r\n",
      "DOH_all.txt.conll   MAK_all.txt.xml     WAJ_all.txt.conll   XIY_all.txt.xml\r\n",
      "DOH_all.txt.xml     OUT_all.txt.conll   WAJ_all.txt.xml     XUL_all.txt.conll\r\n",
      "FAJ_all.txt.conll   OUT_all.txt.xml     WAJ_all2.txt.conll  XUL_all.txt.xml\r\n",
      "FAJ_all.txt.xml     RUO_all.txt.conll   WAJ_all2.txt.xml    \u001b[1m\u001b[34mmerged_conll\u001b[m\u001b[m/\r\n",
      "HAT_all.txt.conll   RUO_all.txt.xml     XIH_all.txt.conll\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Downloads/stanford-corenlp-full-2016-10-31/coref/conll_xml/merged_conll\n"
     ]
    }
   ],
   "source": [
    "cd merged_conll/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Downloads/stanford-corenlp-full-2016-10-31/coref/conll_xml\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHJ_all.txt_merge.conll   LIS_all.txt_merge.conll   WAJ_all.txt_merge.conll\r\n",
      "CHX_all.txt_merge.conll   MAK_all.txt_merge.conll   WAJ_all2.txt_merge.conll\r\n",
      "DIL_all.txt_merge.conll   OUT_all.txt_merge.conll   XIH_all.txt_merge.conll\r\n",
      "DOH_all.txt_merge.conll   RUO_all.txt_merge.conll   XIJ_all.txt_merge.conll\r\n",
      "FAJ_all.txt_merge.conll   SHH_all.txt_merge.conll   XIN_all.txt_merge.conll\r\n",
      "HAT_all.txt_merge.conll   SUC_all.txt_merge.conll   XIY_all.txt_merge.conll\r\n",
      "KOF_all.txt_merge.conll   TIK_all.txt_merge.conll   XUL_all.txt_merge.conll\r\n"
     ]
    }
   ],
   "source": [
    "ls merged_conll/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "path='merged_conll/'\n",
    "files=[f for f in listdir(path) if f.endswith('merge.conll') ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHJ 261\n",
      "CHX 504\n",
      "DIL 368\n",
      "DOH 773\n",
      "FAJ 495\n",
      "HAT 273\n",
      "KOF 177\n",
      "LIS 320\n",
      "MAK 136\n",
      "OUT 258\n",
      "RUO 365\n",
      "SHH 443\n",
      "SUC 336\n",
      "TIK 92\n",
      "WAJ 897\n",
      "XIH 652\n",
      "XIJ 252\n",
      "XIN 291\n",
      "XIY 381\n",
      "XUL 575\n"
     ]
    }
   ],
   "source": [
    "conll_dict={}\n",
    "for f in files:\n",
    "    print f[:3],\n",
    "    g=open(path+f,'r').read().split('\\n')\n",
    "    i=-1\n",
    "    while g[i]=='' or g[i].startswith('#'):\n",
    "        i=i-1\n",
    "    last_line=g[i]\n",
    "    last_sent=last_line.split('\\t')[0]\n",
    "    print last_sent\n",
    "    conll_dict[f[:3]]=last_sent\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "true_dict=pickle.load(open('true_dict.pkl','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DIL': 368, 'DOH': 773, 'SUC': 336, 'RUO': 365, 'WAJ': 897, 'XIH': 652, 'CHJ': 261, 'TIK': 92, 'SHH': 443, 'XIN': 291, 'KOF': 177, 'FAJ': 495, 'XUL': 575, 'LIS': 320, 'CHX': 504, 'XIY': 381, 'MAK': 136, 'HAT': 273, 'XIJ': 252, 'OUT': 258} {'DIL': '367', 'DOH': '770', 'SUC': '333', 'RUO': '365', 'WAJ': '443', 'XIH': '652', 'CHJ': '261', 'TIK': '91', 'XIN': '291', 'KOF': '177', 'FAJ': '490', 'SHH': '440', 'XUL': '575', 'LIS': '320', 'CHX': '499', 'XIY': '381', 'MAK': '136', 'HAT': '272', 'XIJ': '252', 'OUT': '254'}\n"
     ]
    }
   ],
   "source": [
    "print true_dict,conll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k in true_dict.keys():\n",
    "    if int(true_dict[k])!=int(conll_dict[k]):\n",
    "        print k,true_dict[k],conll_dict[k]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the above ones minus WAJ are incorrect. The CHJ was incorrect and I corrected it. The WAJ has two parts, which add up to the right number, but I need to re-merge the sentID. below.\n",
    "\n",
    "# update: after I re-run the coreNLP, everything is correctly parsed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waj='merged_conll/WAJ_all2.txt_merge.conll'\n",
    "#waj has 454, waj2 has 443. We need to add 454 to all sentID in waj2.\n",
    "\n",
    "f=open(waj,'r').read().split('\\n')\n",
    "new_lines=[]\n",
    "for l in f:\n",
    "    if l=='' or l.startswith('#'):\n",
    "        continue\n",
    "    line=l.split('\\t')\n",
    "    line[0]=str(int(line[0])+454)\n",
    "    line[1]=str(int(line[1])+5163)\n",
    "    new_lines.append(line)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['897', '9568', '14', '.', '.', 'PU', 'O', '6', 'punct', '_']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lines[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_waj2='WAJ_all2.txt_merge_corrected.conll'\n",
    "g=open(new_waj2,'w').close()\n",
    "g=open(new_waj2,'a')\n",
    "for line in new_lines:\n",
    "    l='\\t'.join(line)\n",
    "    g.write(l+'\\n')\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIL\n",
      "DOH\n",
      "SUC\n",
      "WAJ\n",
      "TIK\n",
      "SHH\n",
      "FAJ\n",
      "CHX\n",
      "HAT\n",
      "OUT\n"
     ]
    }
   ],
   "source": [
    "for k in true_dict.keys():\n",
    "    if int(true_dict[k])!=int(conll_dict[k]):\n",
    "        print k\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
