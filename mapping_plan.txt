==============5/31
1. after I collapsed POS tags, the classification accuracy becomes a little worse.but i think this is the right thing to do as it is now less sparse. the worse results may point to the general unusefulness of the pos tags,which is understandable.

2. after I collapsed func tags (by :), the classification accuracy jumped. 

3. after I collapsed both POS and func, and remove <5 count in R, I was able to plot the feature important plot for the varImp() method.

4.after I replaced nuclear vowel features (3 in bigram) with vowel features (7 per vowel), the classification accuracy jumped again. These work better than the 7 features from yesterday. it seems though that when we remove pos tag and func, results generally improve, if not taht much.(but of course, i can't have performed exhaustive sub sets of features to get the absolute best, this is just in the ballpark)

best so far: 55.20% (tone134)
starting_pitch
ending_pitch
sent_position
is_entity
tok_bound1
tok_bound2
tok_bound3
singleton
is_nasal1
is_dipthong1
is_high1
is_low1
is_front1
is_back1
is_round1
is_nasal2
is_dipthong2
is_high2
is_low2
is_front2
is_back2
is_round2
is_nasal3
is_dipthong3
is_high3
is_low3
is_front3
is_back3
is_round3
prev_tone
next_tone
label


==============5/30
1. We are interested in extracting two more features from the .phons file, but this will require us to map to the .phons file, hopefully won't be too painful.These are phonological features:(1)the onset and neuclear of the syllable; (2)the previous and following tone to this tone n-gram.

2. after performing the classification experiments, it seems that phons features didn't help. We then did feature ablations - and drived the core set of features that gives a boost to the classification (quite a bit). See OneNote->NetworkAnalysis->Shape ML. The core set of feature (on trigram 342 data): 
starting_pitch
ending_pitch
is_entity
tok_bound1
tok_bound2
tok_bound3
singleton

3. now we are still building the community partitions on the macbook Pro. Meanwhile there are a few things to do and decide: (1)writing and organization; (2)deciding the analysis we will present. you can present classification results on all of unigram, bigram, and trigram data. That is a lot to present. Then you also need to look at feature significance. You can't do manual ablation on all data sets. you can first look at a few data sets and see if the ablation results generalize; then you can use R to run the significance of features; 





==============5/17
1. use phons file to verify that 12_13_14 are tones 1,3,4.

2. map 12_13_14 onto tokens: there are 11 tokens in this sentence (CHJ00008.txt), so syl_12,13,14 is mapped to token 7,8,9. if a sequence (ngram) is mapped onto more than 1 token, it is safe to say that the boundary (token boundary) is crossed. notice that the next step should actually precede this step in practice.

3. however, in real time, we have a conll file with sentence ID but not directly the sentence file name (CHJ00008 is the 7th sentence, since 00007 is missing), so we need a mapping from file name (CHJ00008) to sentence number ID(Sent#7). basically this can be a dict from file name to its order when you list all files in the directory that begins with "CHJ".

4. we then can use token number to extract features. 
